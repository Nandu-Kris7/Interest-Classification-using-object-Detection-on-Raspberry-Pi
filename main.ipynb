{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a766c7f8",
   "metadata": {},
   "source": [
    "# Real-Time Pose-Based Attention Analysis on Raspberry Pi #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd41ad",
   "metadata": {},
   "source": [
    "### Importing necessary libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ef1e2",
   "metadata": {},
   "source": [
    "### Load the Tensorflow Lite Model and allocate tensors ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/media/kris/NITRO/movenet_lightning.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_size = input_shape[1]  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadeabea",
   "metadata": {},
   "source": [
    "#### Resize the frame to the required input dimensions and cast to uint8. This is appropriate when using a quantized TFLite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    img = cv2.resize(frame, (input_size, input_size))\n",
    "    input_data = np.expand_dims(img, axis=0).astype(np.uint8)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11fedbd",
   "metadata": {},
   "source": [
    "#### Calculate head tilt (in degrees) using the positions of the eyes. keypoints: an array of shape [17, 3] where each is [y, x, score]. Uses keypoints: 1: Left eye, 2: Right eye. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_head_tilt(keypoints, conf_threshold=0.4):\n",
    "    nose = keypoints[0]\n",
    "    left_eye = keypoints[1]\n",
    "    right_eye = keypoints[2]\n",
    "    if nose[2] > conf_threshold and left_eye[2] > conf_threshold and right_eye[2] > conf_threshold:\n",
    "\n",
    "        dx = right_eye[1] - left_eye[1]\n",
    "        dy = right_eye[0] - left_eye[0]\n",
    "        angle = math.degrees(math.atan2(dy, dx))\n",
    "        return angle\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962be8e",
   "metadata": {},
   "source": [
    "Analyze the pose to infer attention.\n",
    "    \n",
    "    Heuristics used:\n",
    "      - **Head Position:** Average y-coordinate of shoulders (points 5 and 6) versus nose (point 0).\n",
    "        If the nose is not sufficiently above the shoulders (by a small margin), flag as \"head drooping.\"\n",
    "      - **Head Tilt:** If the absolute head tilt angle exceeds 15 degrees, flag as \"excessive head tilt.\"\n",
    "      - **Hand Positions:** Check if the left or right wrist (points 9 and 10) is above the corresponding shoulder.\n",
    "    \n",
    "    Returns a tuple (attention, feedback) where:\n",
    "      - `attention` is a boolean (True if the person is considered attentive).\n",
    "      - `feedback` is a list of strings that explain factors suggesting inattention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a313d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_attention(keypoints, head_tilt, conf_threshold=0.4):\n",
    "    attention = True\n",
    "    feedback = []\n",
    "    nose = keypoints[0]\n",
    "    left_eye = keypoints[1]\n",
    "    right_eye = keypoints[2]\n",
    "    left_shoulder = keypoints[5]\n",
    "    right_shoulder = keypoints[6]\n",
    "    left_wrist = keypoints[9]\n",
    "    right_wrist = keypoints[10]\n",
    "\n",
    "    avg_shoulder_y = (left_shoulder[0] + right_shoulder[0]) / 2.0\n",
    "\n",
    "    if nose[0] > avg_shoulder_y - 0.05:\n",
    "        attention = False\n",
    "        feedback.append(\"Head drooping\")\n",
    " \n",
    "    if abs(head_tilt) > 15:\n",
    "        attention = False\n",
    "        feedback.append(\"Excessive head tilt\")\n",
    "\n",
    "    if left_wrist[2] > conf_threshold and left_wrist[0] < left_shoulder[0]:\n",
    "        attention = False\n",
    "        feedback.append(\"Left hand raised\")\n",
    "    if right_wrist[2] > conf_threshold and right_wrist[0] < right_shoulder[0]:\n",
    "        attention = False\n",
    "        feedback.append(\"Right hand raised\")\n",
    "    \n",
    "    return attention, feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7951d7d",
   "metadata": {},
   "source": [
    "#### Creating a CSV file to store the data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"/home/kris/Documents/Project/pose_data.csv\"\n",
    "csv_file = open(csv_filename, mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"timestamp\", \"head_tilt\", \"attention\", \"feedback\", \"keypoints\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823c18e",
   "metadata": {},
   "source": [
    "##### Main code #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_data = preprocess_frame(frame)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    keypoints = keypoints_with_scores[0, 0, :, :] \n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    for kp in keypoints:\n",
    "        if kp[2] > 0.4: \n",
    "            cx = int(kp[1] * w)\n",
    "            cy = int(kp[0] * h)\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 255, 0), -1)\n",
    "\n",
    "    head_tilt = calculate_head_tilt(keypoints)\n",
    " \n",
    "    attention, feedback = analyze_attention(keypoints, head_tilt)\n",
    "\n",
    "    if attention:\n",
    "        status_text = \"Attentive\"\n",
    "        status_color = (0, 255, 0)  \n",
    "    else:\n",
    "        status_text = \"Not Attentive: \" + \", \".join(feedback)\n",
    "        status_color = (0, 0, 255)  \n",
    "\n",
    "    cv2.putText(frame, f\"Head Tilt: {head_tilt:.1f} deg\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    cv2.putText(frame, status_text, (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)\n",
    "\n",
    "    cv2.imshow(\"Pose Detection & Attention Analysis\", frame)\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    feedback_json = json.dumps(feedback)\n",
    "    keypoints_json = json.dumps(keypoints.tolist())\n",
    " \n",
    "    csv_writer.writerow([timestamp, head_tilt, attention, feedback_json, keypoints_json])\n",
    "    csv_file.flush()  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
